\documentclass[a4paper, 12pt]{mwart}

\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage[top = 2.5cm, bottom = 2.5cm, left = 2.5cm, right = 2.5cm]{geometry}

\usepackage{enumitem}
\usepackage{amsmath, amsfonts, amssymb, mathtools, amsthm}
\usepackage{icomma}
\mathtoolsset{showonlyrefs}

\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Lin}{Lin}

\newcommand*{\im}{\mathrm{I}}
\newcommand*{\iu}{\mathrm{i}}
\newcommand*{\e}{\mathrm{e}}

\usepackage{bbold}
%\DeclareMathAlphabet{\mathbbold}{U}{bbold}{m}{n}

\theoremstyle{definition}
\newtheorem{definicja}{Def}[section]
\theoremstyle{plain}
\newtheorem{twierdzenie}{TW}[section]
\theoremstyle{remark}
\newtheorem{wniosek}{Wniosek}[section]

%strona tytułowa
\author{skryba Łukasz Pawlak}
\title{Definicje i Twierdzenia z Algebry M2}
\date{Wykłady w roku 2021 \\ ostatnia kompilacja \today}

\begin{document}
\maketitle
\section{Przekształcenia liniowe}
\begin{definicja}
	Niech będzie dane odwzorowanie $T: V \to W$, gdzie $V, W$ \ppauza przestrzenie liniowe nad ciałem $\mathbb{K}$.
	Przekształcenie to nazywa \emph{się przekształceniem liniowym}, jeżeli:
	\begin{enumerate}
		\item Jest to homomorfizm, czyli
		\begin{equation}
			\left(\forall v_1, v_2 \in V\right)\left(T(v_1 + v_2) = T(v_1) + T(v_2)\right).
		\end{equation}
		\item Jest to przekształcenie jednorodne, czyli
		\begin{equation}
			\left(\forall \alpha \in \mathbb{K}\right)\left(\forall v \in V\right)\left(T(\alpha v) = \alpha T(v)\right).
		\end{equation}
	\end{enumerate}
\end{definicja}
\begin{definicja}
	Zbiór przekształceń liniowych z $V$ w $W$ oznaczamy $L(V, W)$.
	Zbiór przekształceń liniowych z $V$ w $V$ oznaczamy $L(V)$.
\end{definicja}
\begin{definicja}
	\emph{Jądrem} przekształcenia liniowego $T$ nazywamy zbiór
	\begin{equation}
		\Ker T = T^{-1}(0) = \left\{v \in V: T(v) = 0\right\}.
	\end{equation}
	\emph{Obrazem} przekształcenia liniowego $T$ nazywamy zbiór
	\begin{equation}
		\Ima T = T[V] = \left\{w \in W: \left(\exists v \in V\right)\left(T(v) = w\right)\right\}.
	\end{equation}
\end{definicja}
\begin{twierdzenie}
	Jeżeli $V, W$ \ppauza przestrzenie liniowe nad ciałem $\mathbb{K}$, przy czym $\dim V < \infty$ oraz $T \in L(V, W)$ to
	\begin{equation}
		\dim V = \dim (\Ker T) + \dim (\Ima T)
	\end{equation}
\end{twierdzenie}
\begin{definicja}
	\emph{Defekt} i \emph{rząd} przekształcenia $T$ określamy jako odpowiednio
	\begin{align}
		\operatorname{def} T &= \dim \Ker T, \\
		\operatorname{rz}  T &= \dim \Ima T.
	\end{align}
\end{definicja}
\begin{twierdzenie}
	Niech $V, W$ \ppauza przestrzenie liniowe nad ciałem $\mathbb{K}$, przy czym niech $\dim~V = n <~\infty$. Niech $B = \left\{e_1, e_2, \ldots, e_n\right\}$ będzie bazą przestrzeni $V$. Niech $T, S \in L(V, W)$. Wtedy
	\begin{equation}
		T = S \quad \iff \quad \left(\forall i \in [n]\right)\left(T(e_i) = S(e_i)\right).
	\end{equation}
\end{twierdzenie}
\begin{wniosek}
	Przekształcenie liniowe wystarczy zdefiniować na wektorach bazy.
\end{wniosek}
\begin{definicja}
	Przekształcenie $T \in L(V, W)$ nazywamy \emph{izomorfizmem}, gdy jest bijekcją. Jeśli ponadto $V = W$, to $T$ nazywamy \emph{automorfizmem}.
\end{definicja}
\begin{twierdzenie}
	Jeśli $T \in L(V, W)$ oraz $\dim V = \dim W = n$, to $\circlearrowleft$:
	\begin{enumerate}
		\item $T$ jest suriekcją (,,na''),
		\item $\operatorname{rz}T = n$,
		\item $\operatorname{def}T = 0$,
		\item $T$ jest iniekcją (1-1),
		\item $T$ jest izomorfizmem.
	\end{enumerate}
\end{twierdzenie}
\begin{twierdzenie}
	Jeśli $V$ i $W$ są przestrzeniami liniowymi nad ciałem $\mathbb{K}$, to $L(V, W)$  z naturalnie zdefiniowanymi operacjami dodawania funkcji i mnożenia funkcji przez skalar, jest przestrzenią liniową nad ciałem $\mathbb{K}$.
\end{twierdzenie}
\begin{definicja}
	Uporządkowaną czwórkę $(A, +, \circ, \cdot_\mathbb{K})$ nazywamy \emph{algebrą z jednością nad ciałem $\mathbb{K}$}, jeśli zachodzą następujące warunki:
	\begin{enumerate}
		\item $(A, +, \cdot_\mathbb{K})$ jest przestrzenią liniową nad ciałem $\mathbb{K}$,
		\item $(A, +, \circ)$ jest pierścieniem z jednością,
		\item $\left(\forall \alpha \in \mathbb{K}\right)\left(\forall x, y \in A\right)\left[(\alpha \cdot_\mathbb{K} x) \circ y = x \circ (\alpha \cdot_\mathbb{K} y) = \alpha \cdot_\mathbb{K} (x \circ y)\right]$
	\end{enumerate}
\end{definicja}
\begin{twierdzenie}
	Jeśli $V$ jest przestrzenią liniową nad ciałem $\mathbb{K}$, a $\circ$ oznacza złożenie funkcji, to $\left(L(V), +, \circ, \cdot_\mathbb{K}\right)$ jest algebrą z jednością nad ciałem $\mathbb{K}$.
\end{twierdzenie}
\begin{twierdzenie}
	Jeśli $A = \left\{v_1, v_2, \ldots, v_n\right\}$ \ppauza baza przestrzeni $V$, $B = \left\{w_1, w_2, \ldots, w_m\right\}$ \ppauza baza przestrzeni $W$, to zbiór przekształceń $T_{i,j} \in L(V, W)$ postaci
	\begin{align}
		T_{i,j}(v_j) &= w_i, &&\text{dla } i \in [m], \quad j \in [n] \\
		T_{i,j}(v_k) &= \vec{0}, &&\text{dla } i \in [m], \quad k \neq j
	\end{align}
	jest bazą przestrzeni $L(V, W)$.
\end{twierdzenie}
\begin{definicja}
	Niech $T \in L(V, W)$, $A = \left\{v_1, v_2, \ldots, v_n\right\}, B = \left\{w_1, w_2, \ldots, w_m\right\}$ \ppauza bazy przestrzeni $V$ i $W$ odpowiednio. Wtedy dla każdego indeksu $i$ zachodzi
	\begin{equation}
		T(v_i) = \sum_{j = 1}^m t_{ji}w_j
	\end{equation}
	dla pewnych $t_{ji} \in \mathbb{K}$. Macierz $\left[t_{ji}\right]_{m \times n}$ nazywamy \emph{macierzą przekształcenia liniowego $T$} w bazach $A$ w przestrzeni $V$ i $B$ w przestrzeni $W$. Oznaczmy ją $M_B^A(T)$.
\end{definicja}
\begin{definicja}
	Niech $B = \left\{v_1, v_2, \ldots, v_n \right\}$, $B' = \left\{v_1', v_2', \ldots, v_n' \right\}$. Macierz $P^B_{B'} = [p_{ji}]_{n \times n}$ taką, że dla dowolnego indeksu $i$ zachodzi
	\begin{equation}
		v_i' = \sum_{j = 1}^n p_{ji}v_j
	\end{equation}
	nazywamy \emph{macierzą przejścia} z bazy $B$ do bazy $B'$.
\end{definicja}
\begin{twierdzenie}
	Jeżeli $T \in L(V, W)$, oraz $A, A'$ \ppauza bazy $V$, $B, B'$ \ppauza bazy $W$, to
	\begin{equation}
		 M^{A'}_{B'}(T) = P^{B'}_B \cdot M^A_B(T) \cdot P^A_{A'}.
	\end{equation}
	Jeżeli $V = W$, to możemy napisać $P^A_{A'} = P$ i wówczas $P^{A'}_A = P^{-1}$.
\end{twierdzenie}
Macierze przejścia i przekształcenia zapisujemy często w uproszczonej notacji, pomijając indeksy sugerujące bazy. Należy jednak uważać, aby taki zapis był jednoznaczny.
\begin{definicja}
	Niech $A, B \in \mathbb{K}^{n \times n}$. Mówimy, że macież $A$ jest \emph{podobna} do macierzy $B$, jeśli istnieje nieosobliwa macierz $P \in \mathbb{K}^{n \times n}$ taka że
	\begin{equation}
		B = P^{-1} A P.
	\end{equation}
\end{definicja}
\begin{twierdzenie}
	Jeśli $V$ jest przestrzenią liniową nad ciałem $\mathbb{K}$ oraz $\dim V  = n < \infty$, to algebry $L(V)$ i $M_n(\mathbb{K})$ są izomorficzne (mnożenie macierzy odpowiada składaniu przekształceń liniowych, a dodawanie macierzy dodawaniu funkcji).
\end{twierdzenie}
\begin{twierdzenie}
	Jeśli $T \in L(V, W)$ jest bijekcją, to $\dim V = \dim W$, istnieje przekształcenie odwrotne $T^{-1}$ oraz jest to przekształcenie liniowe, czyli $T^{-1} \in L(W, V)$.
\end{twierdzenie}
\begin{twierdzenie} % z ćwiczeń
	Jeśli $T \in L(V, W)$ jest przekształceniem różnowartościowym (iniekcją) i
	$A = \left\{v_1, v_2, \ldots v_n\right\}$ jest zbiorem wektorów liniowo niezależnych, to zbiór
	\begin{equation}
		T[A] = \left\{T(v_1), T(v_2), \ldots, T(v_n)\right\}
	\end{equation}
	jest zbiorem wektorów liniowo niezależnych.
\end{twierdzenie}
\begin{twierdzenie} % z ćwiczeń
	Jeśli $T \in L(V, W)$ jest przekształceniem na przestrzeń $W$ (suriekcją) i $A = \left\{v_1, v_2, \ldots v_n\right\}$ jest zbiorem rozpinającym $V$, czyli $
	V =\Lin(A)$, to
	\begin{equation}
		W = \Lin(T[A]) = \Lin(T(v_1), T(v_2), \ldots, T(v_n)).
	\end{equation}
\end{twierdzenie}
\begin{wniosek}
	Jeśli $T \in L(V, W)$ jest bijekcją, to przekształca bazę $V$ w bazę $W$.
\end{wniosek}
\begin{definicja}
	Przekształcenie $T \in L(V, W)$ jest \emph{nieosobliwe}, Jeżeli nieosobliwa jest macierz tego przekształcenia w dowolnej bazie.
\end{definicja}
\begin{twierdzenie}
	Niech $T \in L(V, W)$, gdzie $\dim V < \infty$. Wtedy
	\begin{equation}
		T \text{ jest odwracalna (istnieje $T^{-1}$)}  \quad \iff \quad T \text{ jest nieosobliwa}.
	\end{equation}
\end{twierdzenie}
\begin{definicja}
	Niech $V$ \ppauza przestrzeń liniowa nad ciałem $\mathbb{K}$, i niech $V_1, V_2$ \ppauza podprzestrzenie liniowe przestrzeni $V$. Zbiór
	\begin{equation}
		V_1 + V_2 = \left\{v_1 + v_2 \in V: v_1 \in V_1 \land v_2 \in V_2\right\}
	\end{equation}
	nazywamy \emph{sumą podprzestrzeni} $V_1$ i $V_2$.
\end{definicja}
\begin{twierdzenie}
	Jeśli $V_1 \leq V$ oraz $V_2 \leq V$, to $V_1 + V_2 \leq V$.
	Słownie: jeśli $V_1, V_2$ są podprzestrzeniami liniowymi $V$, to $V_1 + V_2$ jest podprzestrzenią liniową $V$.
\end{twierdzenie}
\begin{definicja}
	Suma podprzestrzeni $V_1 + V_2$ nazywa się \emph{sumą prostą}, jeżeli każdy wektor $v \in V_1 + V_2$  można przedstawić jednoznacznie w postaci sumy wektorów $v = v_1 + v_2$ dla pewnych $v_1 \in V_1$, $v_2 \in V_2$. Sumę prostą oznaczamy $V_1 \oplus V_2$.
\end{definicja}
\begin{twierdzenie}
	Niech $V_1, V_2 \leq V$ \ppauza przestrzenie liniowe. Wtedy
	\begin{equation}
		V_1 + V_2 \quad \text{jest sumą prostą} \quad \iff \quad V_1 \cap V_2 = \{\vec{0}\}.
	\end{equation}
\end{twierdzenie}
\begin{twierdzenie}
	Niech $V_1, V_2 \leq V$, $\dim V = n < \infty$. Wtedy
	\begin{equation}
		\dim (V_1 + V_2) = \dim V_1 + \dim V_2 - \dim (V_1 \cap V_2).
	\end{equation}
\end{twierdzenie}
\section{Wektory i wartości własne przekształceń liniowych i macierzy}
\begin{definicja}
	Niech $V$ \ppauza przestrzeń liniowa, $T \in L(V)$, $W \leq V$. Mówimy, że  \emph{$W$ jest niezmiennicza względem $T$}, jeżeli
	\begin{equation}
		T[W] \subseteq W.
	\end{equation}
\end{definicja}
\begin{definicja}
	Niech $V$ \ppauza przestrzeń liniowa nad ciałem $\mathbb{K}$, $T \in L(V)$. Element $\lambda \in \mathbb{K}$ nazywamy \emph{wartością własną} przekształcenia $T$, jeśli istnieje wektor $v \in V \setminus \{\vec{0}\}$ taki, że\begin{equation}
		T(v) = \lambda v.
	\end{equation}
	Wówczas wektor $v$ nazywamy \emph{wektorem własnym odpowiadającym wartości własnej $\lambda$}.
\end{definicja}
\begin{wniosek}
	Jeśli $v$ jest wektorem własnym przekształcenia $T \in L(V)$, to $\Lin (v)$ jest podprzestrzenią niezmiennicza względem $T$.
\end{wniosek}
\begin{definicja}
	Niech $T \in L(V)$ i niech $\lambda$ będzie wartością własną przekształcenia $T$. Wtedy zbiór
	\begin{equation}
		V_\lambda = \left\{v \in V: T(v) = \lambda v\right\}
	\end{equation}
	jest podprzestrzenią $V$ i nazywamy go \emph{przestrzenią własną} przekształcenia $T$ odpowiadającą wartości własnej $\lambda$. Wszystkie elementy poza wektorem zerowym w tej przestrzeni są wektorami własnymi odpowiadającymi wartości własnej $\lambda$.
\end{definicja}
\begin{twierdzenie}
	Niech $T \in L(V)$, $\dim V < \infty$ i niech $\lambda_1, \lambda_2, \ldots, \lambda_m$ \ppauza \emph{różne} wartości własne przekształcenia $T$. Jeśli $v_1, v_2, \ldots, v_m$ \ppauza wektory własne odpowiadające odpowiednim wartościom własnym $\lambda_i$, to są to wektory liniowo niezależne.
\end{twierdzenie}
\begin{wniosek}
	Jeśli $T \in L(V)$, $\dim V = n < \infty$, to $T$ ma co najwyżej $n$ różnych wartości własnych.
\end{wniosek}
\begin{twierdzenie}
	Jeśli $T \in L(V)$, $\dim V = n < \infty$ i $T$ ma $n$ różnych wartości własnych, to macierz przekształcenia $T$ w bazie wektorów własnych jest diagonalna.
\end{twierdzenie}
\begin{definicja}
	Jeśli $A \in M_n(\mathbb{K})$, to wektor $v \in \mathbb{K}^n$ nazywamy \emph{wektorem własnym macierzy $A$}, jeżeli nie jest to wektor serowy, oraz
	\begin{equation}
		A \cdot v = \lambda v,
	\end{equation}
	dla pewnej $\lambda \in \mathbb{K}$.
\end{definicja}
\begin{definicja}
	Wielomian
	\begin{equation}
		W(\lambda) = \det (A - \lambda \im)
	\end{equation}
	nazywamy \emph{wielomianem charakterystycznym} macierzy $A$. Równanie postaci
	\begin{equation}
		\det (A - \lambda \im) = 0
	\end{equation}
	nazywamy \emph{równaniem charakterystycznym}.
\end{definicja}
\begin{twierdzenie}
	Wartości własne macierzy $A$, to pierwiastki równania charakterystycznego
	\begin{equation}
		\det (A - \lambda \im) = 0.
	\end{equation}
	Przestrzeń własna odpowiadająca wartości własnej $\lambda$ jest przestrzenią rozwiązań układu jednorodnego
	\begin{equation}
		(A - \lambda \im) \cdot v = \vec 0.
	\end{equation}
\end{twierdzenie}
\begin{twierdzenie} % z ćwiczeń
	Jeśli $T \in L(V)$, to wartości własne macierzy przekształcenia $T$ są takie same w każdej bazie. Są także takie same jak wartości własne przekształcenia $T$.
\end{twierdzenie}
\section{Przestrzenie Euklidesowe} % w zasadzie unitarne, ale przykłady z R^n
\begin{definicja}
	Niech $V$ będzie przestrzenią liniową nad ciałem $\mathbb{R}$. Funkcję
	\begin{equation}
		F:V \times V \to \mathbb{R}
	\end{equation}
	nazywamy \emph{iloczynem skalarnym} jeśli dla dowolnych $u, v, w \in \mathbb{R}$ oraz $\lambda \in V$ spełnia następujące warunki:
	\begin{enumerate}
		\item $F(u, v) = F(v, u)$ \quad (symetria),
		\item $F(\lambda u, v) = \lambda F(u, v)$ \quad (jednorodność ze względu na pierwszy argument),
		\item $F(u + v, w) = F(u, w) + F(v, w)$ \quad (addytywność ze względu na pierwszy argument),
		\item $F(v, v) \geq 0$ \quad (dodatnia określoność),
		\item $F(v, v) = 0 \iff v = \vec 0$.
		% ten gość pewnie powinien siedzieć w preambule, ale tak jest jakoś czytelnije, a działa.
		\newcounter{warunkiIloczynuSkalarnego}
		\setcounter{warunkiIloczynuSkalarnego}{\value{enumi}}
	\end{enumerate}
	Iloczyn skalarny oznaczamy $F(u, v) = \left<u, v\right>$.
\end{definicja}
\begin{wniosek}
	Powyższe warunki dają dodatkowe własności:
	\begin{enumerate}
		\setcounter{enumi}{\value{warunkiIloczynuSkalarnego}}
		\item $F(u, \lambda v) = \lambda F(u, v)$ \quad (jednorodność ze względu na drugi argument),
		\item $F(u, v + w) = F(u, v) + F(u, w)$ \quad (addytywność ze względu na drugi argument).
	\end{enumerate}
\end{wniosek}
\begin{definicja}
	\emph{Formą dwuliniową} nad przestrzenią liniową $V$ nad ciałem $\mathbb{K}$ nazywamy funkcję
	\begin{equation}
		F:V \times V \to \mathbb{K}
	\end{equation}
	spełniającą dla dowolnych $u, v, w \in V$ oraz $\lambda \in \mathbb{K}$:
	\begin{enumerate}
		\item $F(\lambda u, v) = \lambda F(u, v)$ \quad (jednorodność ze względu na pierwszy argument),
		\item $F(u, \lambda v) = \lambda F(u, v)$ \quad (jednorodność ze względu na drugi argument),
		\item $F(u + v, w) = F(u, w) + F(v, w)$ \quad (addytywność ze względu na pierwszy argument),
		\item $F(u, v + w) = F(u, v) + F(u, w)$ \quad (addytywność ze względu na drugi argument).
	\end{enumerate}
	Lub równoważnie 
	\begin{enumerate}
		\item $F(\lambda u + v, w) = \lambda F(u, w) + F(v, w)$,
		\item $F(u, \lambda v + w) = F(u, v) +  \lambda F(u, w)$.
	\end{enumerate}
	czyli liniowość względem obu argumentów.
\end{definicja}
\begin{wniosek}
	Iloczyn skalarny to forma dwuliniowa z dodatkowym założeniem symetrii i dodatniej określoności. % i nie wiem czy ostatni punkt też trzeba osobno wymienić :')
\end{wniosek}
\begin{definicja}
	Parę $\left(V, \left< \cdot, \cdot \right> \right)$, gdzie $V$ \ppauza przestrzeń liniowa $n$\dywiz wymiarowa nad $\mathbb{R}$, $\left< \cdot, \cdot \right>$ \ppauza iloczyn skalarny o wartościach w $\mathbb{R}$, nazywamy
	\emph{przestrzenią Euklidesową} rzeczywistą.
\end{definicja}
\begin{definicja}
	Wektory $v, w$ w przestrzeni Euklidesowej rzeczywistej $V$ nazywamy \emph{ortogonalnymi}, jeśli
	\begin{equation}
		\left< v, w \right> = 0.
	\end{equation}
	Jeśli tak jest, o własność tę oznaczamy $v \perp w$.
\end{definicja}
\begin{definicja}
	Bazę $B = \left\{e_1, e_2, \ldots, e_n\right\}$ przestrzeni Euklidesowej rzeczywistej $V$ nazywamy \emph{ortogonalną}, jeśli
	\begin{equation}
		\left(\forall i \in [n]\right)\left(\forall j \in [n] \setminus \{i\}\right)\left(e_i \perp e_j\right).
	\end{equation}
\end{definicja}
\begin{definicja}
	Niech $V$ \ppauza przestrzeń liniowa nad ciałem $\mathbb{K}$ ($\mathbb{R}$ lub $\mathbb{C}$). Funkcję $F:V \to \mathbb{R}$ nazywamy \emph{normą}, jeżeli dla dowolnych $u, v \in V$, $\lambda \in \mathbb{K}$ spełnia
	\begin{enumerate}
		\item $F(v) \geq 0$,
		\item $F(\lambda v) = |\lambda|F(v)$,
		\item $F(u+v) \leq F(u) + F(v)$,
		\item $F(v) = 0 \iff v = \vec 0$.
	\end{enumerate}
	Normę oznaczamy przez
	\begin{equation}
		F(v) = ||v||.
	\end{equation}
\end{definicja}
\begin{twierdzenie}[Nierówność Cauchy'ego \ppauza Schwartza]
	W przestrzeni Euklidesowej dla dowolnych wektorów $u, v$ zachodzi nierówność\begin{equation}
		|\left< u, v \right>| \leq \sqrt{\left< u, u \right>} \sqrt{\left< v, v \right>}
	\end{equation}
\end{twierdzenie}
\begin{twierdzenie}
	W przestrzeni Euklidesowej z iloczynem skalarnym $\left< \cdot, \cdot \right>$ funkcja
	\begin{equation}
		\|u\| = \sqrt{\left< u, u \right>}
	\end{equation}
	jest normą. Nazywamy ją normą \emph{indukowaną} przez iloczyn skalarny.
\end{twierdzenie}
\begin{definicja}
	Bazę ortogonalną $B = \left\{e_1, e_2, \ldots, e_n\right\}$ przestrzeni Euklidesowej rzeczywistej $V$ nazywamy \emph{ortonormalną}, jeśli
	\begin{equation}
		\left(\forall i \in [n]\right)\left(\|e_i\| = 1\right).
	\end{equation}
	Warunek ortonormalności możemy zapisać przy pomocy delty Kroneckera:
	\begin{equation}
		\left< v_i, v_j \right> = \delta_{ij} = 
		\begin{cases}
			1 \quad \text{gdy } i = j \\
			0 \quad \text{gdy } i \neq j.
		\end{cases}
	\end{equation}
\end{definicja}
\begin{definicja}
	Niech $v, w \in V \setminus \{\vec 0\}$, gdzie $\left(V, \left< \cdot, \cdot \right> \right)$ \ppauza przestrzeń Euklidesowa. \emph{Kąt} pomiędzy wektorami $v$ i $w$ definiujemy przy pomocy funkcji cosinus, jako
	\begin{equation}
		\cos \measuredangle (v, w) = \frac{\left< v, w \right> }{\|v\| \|w\|},
	\end{equation}
	przy czym jest to kąt z przedziału $[0, \pi)$
\end{definicja}
\begin{twierdzenie}
	Zbiór niezerowych wektorów ortogonalnych jest liniowo niezależny.
\end{twierdzenie}
\begin{twierdzenie}[Ortogonalizacja Grama \ppauza Schmidta]
	W $n$\dywiz wymiarowej przestrzeni Euklidesowej rzeczywistej istnieje baza ortogonalna. Przy pomocy dowolnej bazy możemy wyznaczyć bazę ortonormalną stosując poniższy algorytm: \\
	Niech $B = \left\{v_1, v_2, \ldots v_n\right\}$ \ppauza baza $\mathbb{R}$.
	\begin{enumerate}
		\item Ustalamy $w_1 = v_1$,
		\item Wektor $w_k$ wyznaczamy jako kombinację liniową wektorów $w_i$ o indeksach mniejszych od $k$ oraz wektora $v_k$:
		\begin{equation}
			w_k = v_k - \sum_{i=1}^{k-1} \frac{\left<w_i, v_k \right>}{\|w_i\|^2} w_i.
		\end{equation}
	\end{enumerate}
\end{twierdzenie}
\begin{wniosek}
	Każdy zbiór wektorów ortonormalnych w $n$\dywiz wymiarowej przestrzeni Euklidesowej rzeczywistej można uzupełnić do bazy ortonormalnej.
\end{wniosek}
\begin{definicja}
	\emph{Dopełnieniem ortogonalnym} przestrzeni $W \leq V$ nazywamy zbiór
	\begin{equation}
		W^\perp = \left\{v \in V: \left(\forall w \in W\right)\left(w \perp v\right)\right\}.
	\end{equation}
\end{definicja}
\begin{definicja}
	\emph{Rzutem ortogonalnym} wektora $v \in V$ na podprzestrzeń $W \leq V$ nazywamy każdy wektor, który w dowolnej bazie ortonormalnej $B = \left\{e_1, e_2, \ldots, e_m\right\}$ podprzestrzeni $W$ ma postać
	\begin{equation}
		w = \sum_{i=1}^{m} \left< v, e_i \right> e_i.
	\end{equation}
\end{definicja}
\begin{twierdzenie}
	Niech $V$ \ppauza przestrzeń Euklidesowa, $W$ \ppauza podprzestrzeń $V$ taka, że $\dim W < \infty$. Wtedy suma $W + W^\perp$ jest sumą prostą oraz
	\begin{equation}
		V = W \oplus W^\perp.
	\end{equation}
\end{twierdzenie}
\begin{twierdzenie}
	Niech $V$ \ppauza przestrzeń Euklidesowa oraz niech $W \leq V$. Wtedy
	\begin{equation}
		{(W^\perp)}^\perp = W.
	\end{equation}
\end{twierdzenie}
Pamiętamy jakie były cyrki, kiedy pisaliśmy że baza przestrzeni jest zbiorem, ale kolejność jest ważna? Okazuje się, że jest pojęcie którego powinniśmy byli wtedy używać.
\begin{definicja}
	\emph{Układem wektorów} z przestrzeni liniowej $V$ nazywamy ciąg wektorów
	\begin{equation}
		\left(v_1, v_2, \ldots\right),
	\end{equation}
	gdzie $v_i \in V$. Może być skończony. Chodzi o to, że kolejność ma znaczenie, ale często potrzebujemy odnosić się do niego jako zbioru.
\end{definicja}
\begin{definicja}
	Niech $V$ będzie $n$\ppauza wymiarową przestrzenią Euklidesową rzeczywistą i niech $B = (v_1, v_2, \ldots v_n)$ \ppauza układ wektorów a przestrzeni $V$. Macierz postaci
	\begin{equation}
		G(v_1, v_2, \dots, v_n) = \begin{bmatrix}
			\left<v_1, v_1\right> & \left<v_1, v_2\right> & \ldots & \left<v_1, v_n\right> \\
			\left<v_2, v_1\right> & \left<v_2, v_2\right> & \ldots & \left<v_2, v_n\right> \\
			\vdots & \vdots & & \vdots \\
			\left<v_i, v_1\right> & \left<v_i, v_2\right> & \ldots & \left<v_i, v_n\right> \\
			\vdots & \vdots & \ddots & \vdots \\
			\left<v_n, v_1\right> & \left<v_n, v_2\right> & \ldots & \left<v_n, v_n\right> \\
		\end{bmatrix}
	\end{equation}
	Nazywamy \emph{Macierzą Grama}. Wyznacznik tej macierzy nazywamy \emph{wyznacznikiem Grama}, i oznaczamy
	\begin{equation}
		\Gamma(v_1, v_2, \ldots, v_n) = \det G(v_1, v_2, \dots, v_n).
	\end{equation}
\end{definicja}
\begin{twierdzenie}
	Jeśli układ $(w_1, w_2, \ldots, w_n)$ jest otrzymany w procesie ortogonalizacji Grama\ppauza Schmidta z układu $(v_1, v_2, \ldots, v_n)$, to
	\begin{equation}
		\Gamma(v_1, v_2, \ldots, v_n) = \Gamma(w_1, w_2, \ldots, w_n) = \prod_{i = 1}^n \|w_i\|
	\end{equation}
\end{twierdzenie}
\begin{wniosek}
	Dla dowolnego układu wektorów $(v_1, v_2, \ldots, v_n)$ w przestrzeni Euklidesowej rzeczywistej zachodzą:
	\begin{enumerate}
		\item $\Gamma(v_1, v_2, \ldots, v_n) \geq 0$,
		\item $\Gamma(v_1, v_2, \ldots, v_n) = 0 \quad \iff \quad$ układ $(v_1, v_2, \ldots, v_n)$ jest liniowo zależny.
	\end{enumerate}
	Badanie wyznacznika macierzy Grama stanowi więc (nie zawsze wygodny) sposób na badanie liniowej niezależności.
\end{wniosek}
\begin{definicja}
	\emph{Iloczynem skalarnym} w przestrzeni liniowej $V$ nad ciałem $\mathbb{C}$ nazywamy funkcję $F\colon V\times V \to \mathbb{C}$ spełniającą dla dowolnych $u, v, w \in V$ oraz $\lambda \in \mathbb{C}$ następujące warunki:
	\begin{enumerate}
		\item $F(\lambda u, v) = \lambda F(u, v)$ \quad (jednorodność ze względu na pierwszy argument),
		\item $F(u + v, w) = F(u, w) + F(v, w)$ \quad (addytywność ze względu na pierwszy argument),
		\item $F(u, v) = \overline{F(v, u)}$ \quad (symetria sprzężona),
		\item $F(v, v) \in [0, \infty)\subseteq\mathbb{R} $\quad (dodatnia określoność),
		\item $F(v, v) = 0 \iff v = \vec 0$.
		\end{enumerate}
\end{definicja}
Różnica pomiędzy iloczynem skalarnym rzeczywistym a~zespolonym polega na tym, że jeden jest formą dwuliniową a~drugi \ppauza półtoraliniową.
\begin{definicja}
	\emph{Formą półtoraliniową} nazywamy funkcję $F\colon V\times V\to \mathbb{C}$ spełniającą dla dowolnych wektorów $u, v, w\in V$ oraz skalara $\alpha\in\mathbb{C}$ następujące warunki:
	\begin{enumerate}
		\item $F(u+v, w) = F(u, w) + F(v, w)$,
		\item $F(u, v+w) = F(u, v) + f(u, w)$,
		\item $F(\alpha v, w) = \alpha F(v, w)$,
		\item $F(v, \alpha w) = \overline\alpha F(v, w)$.
	\end{enumerate}
\end{definicja}
Uwaga: dla iloczynu skalarnego zespolonego także działa Ortogonalizacja Grama\ppauza Schmidta, a~także twierdzenie o wyznaczniku Grama.
\section{Formy dwuliniowe i kwadratowe}
\begin{definicja}
	\emph{Funkcjonałem liniowym} na przestrzeni liniowej $V$ nad ciałem $\mathbb{K}$ nazywamy funkcję $F\colon V\to \mathbb{K}$ taką, że
	\begin{equation}
		F(\alpha x + y) = \alpha F(x) + F(y)
	\end{equation}
	dla dowolnych $x, y \in V$ oraz $\alpha \in \mathbb{K}$. W~skrócie: $F \in L(V, \mathbb{K})$.
\end{definicja}
\begin{definicja}
	Przestrzeń liniową $L(V, \mathbb{K})$ oznaczamy $V^*$ i~nazywamy \emph{przestrzenią dualną} (dual space) do $V$.
\end{definicja}
\begin{definicja}
	\emph{Funkcjonałem dwuliniowym} nazywamy funkcję $F\colon V\times V\to \mathbb{K}$ spełniającą dla dowolnych $u, v, w \in V$ oraz $\alpha \in \mathbb{K}$ następujące warunki:
	\begin{enumerate}
		\item $F(\alpha v + w, u) = \alpha F(v, u) + F(w, u)$,
		\item $F(u, \alpha v + w) = \alpha F(u, v) + F(u, w)$.
	\end{enumerate}
	Zbiór funkcjonałów dwuliniowych na przestrzeni $V$ oznaczamy $L(V\times V, \mathbb{K})$. Stanowi to pewien konflikt oznaczeń, ale nie mówimy o tym.
\end{definicja}
\begin{twierdzenie}
	Niech $V$ będzie przestrzenią liniową nad ciałem $\mathbb{K}$, $B=\left\{e_1, e_2, \ldots, e_n\right\}$ jest bazą $V$ oraz $F$ jest funkcjonałem dwuliniowym. Jeśli $v, w \in V$ oraz
	\begin{equation}
		v = \sum_{i = 1}^{n} v_i e_i, \quad w = \sum_{i = 1}^{n} w_i e_i,
	\end{equation}
	to zachodzi
	\begin{equation}
		F(v, w) = \sum_{i, j = 1}^{n} a_{i, j}v_iw_j
	\end{equation}
	gdzie $a_{i, j} = F(e_i, e_j)$.
\end{twierdzenie}
\begin{definicja}
	Wyrażenie postaci
	\begin{equation}
		\sum_{i, j = 1}^{n} a_{i, j}x_iy_j
	\end{equation}
	nazywamy \emph{formą dwuliniową}.
\end{definicja}
\begin{twierdzenie}
	Funkcjonały dwuliniowe są sobie równe, wtedy i tylko wtedy gdy mają takie same wartości na bazie na obu współrzędnych, czyli kiedy
	\begin{equation}
		F_1(e_i, e_j) = F_2(e_i, e_j).
	\end{equation}
\end{twierdzenie}
\begin{definicja}
	Niech $\dim V = n < \infty$, $F\in L(V\times V, \mathbb{K})$. Macierz
	\begin{equation}
		A = {\left[F(e_i, e_j)\right]}_{n \times n} = 
		\begin{bmatrix}
			F(e_1, e_1) & F(e_1, e_2) & \cdots & F(e_1, e_n) \\
			F(e_2, e_1) & F(e_2, e_2) & \cdots & F(e_2, e_n) \\
			\vdots & \vdots & \ddots & \vdots \\
			F(e_n, e_1) & F(e_n, e_2) & \cdots & F(e_n, e_n)
		\end{bmatrix}
	\end{equation}
	nazywamy \emph{macierzą funkcjonału $F$ w~bazie $B$}.
\end{definicja}
\begin{twierdzenie}
	Istnieje bijekcja między zbiorami $L(V\times V, \mathbb{K})$, $M_n(\mathbb{K})$, gdzie $n = \dim V < \infty$. %Prawdopodobnie możemy mówić o~izomorfizmie przestrzeni liniowych, ale twierdzenie mówi tylko o~bijekcji.
\end{twierdzenie}
\begin{twierdzenie}
	Jeśli $F \in L(V\times V, \mathbb{K})$ gdzie $\dim V = n < \infty$ ma w bazie $B$ macierz $M$, a~w~bazie $B'$ macierz $M'$, to
	\begin{equation}
		M' = P^TMP
	\end{equation}
	gdzie $P$ jest macierzą przejścia z~bazy $B$ do $B'$.
\end{twierdzenie}
\begin{definicja}
	Forma dwuliniowa nazywa się \emph{symetryczną}, jeśli
	\begin{equation}
		\left(\forall v, w\in V\right) F(v, w) = F(w, v).
	\end{equation}
\end{definicja}
\begin{definicja}
	\emph{Rzędem formy dwuliniowej} nazywamy rząd macierzy tej formy w~dowolnej bazie. Jest to wartość niezależna od wyboru bazy.
\end{definicja}
\begin{definicja}
	\emph{Wyróżnikiem formy dwuliniowej} nazywamy wyznacznik macierzy tej formy w zadanej bazie. Ta wartość jest zależna od bazy.
\end{definicja}
\begin{definicja}
	Niech $F \in L(V\times V, \mathbb{K})$ będzie funkcjonałem dwuliniowym symetrycznym. Wtedy funkcja $G\colon V\to \mathbb{K}$ określona wzorem
	\begin{equation}
		G(v) = F(v, v)
	\end{equation}
	nazywa się \emph{funkcjonałem kwadratowym} na przestrzeni $V$. O~funkcjonale $F$ mówimy, że \emph{generuje} on funkcjonał kwadratowy $G$.
\end{definicja}
\begin{wniosek}
	$F$ i $G$ wyznaczają się nawzajem jednoznacznie.
\end{wniosek}
\begin{definicja}
	Jeżeli $B = \left\{e_1, e_2, \ldots, e_n\right\}$ \ppauza wybrana baza $V$, gdzie $\dim V = n < \infty$ i $G$ jest funkcjonałem kwadratowym na $V$ to
	\begin{equation}
		G\left(\sum_{i = 1}^n x_ie_i\right) = F\left(\sum_{i = 1}^n x_ie_i, \sum_{j = 1}^n x_je_j\right) = \sum_{i, j = 1}^n x_ix_jF\left(e_i, e_j\right) = \sum_{i, j = 1}^n x_ix_ja_{i, j}
	\end{equation}
	gdzie $a_{i, j} = F\left(e_i, e_j\right)$. Prawa strona równości nazywa się \emph{formą kwadratową}, natomiast macierz $A = [a_{i, j}]$ nazywa się \emph{macierzą} tej formy (taka sama jak macierz formy dwuliniowej $F$) w bazie $B$.
\end{definicja}
\begin{definicja}
	\emph{Rzędem formy kwadratowej} nazywamy rząd macierzy tej formy.
\end{definicja}
\begin{twierdzenie}
	Rząd formy kwadratowej nie zależy od wyboru bazy.
\end{twierdzenie}
\begin{definicja}
	Mówimy, że funkcjonał kwadratowy $G$ na w bazie $B$ \emph{postać kanoniczną} jeżeli macierz formy jest w tej bazie diagonalna. Wtedy baza $B$ nazywa się \emph{bazą kanoniczną} formy $G$. Mamy więc, że $G$ ma w bazie kanonicznej postać diagonalną, czyli
	\begin{equation}
		G(x) = \sum_{i = 1}^{n} a_{i, i}{x_i}^2
	\end{equation}
\end{definicja}
\begin{twierdzenie}
	Niech $G$ będzie funkcjonałem kwadratowym określonym na przestrzeni liniowej $V$ nad ciałem $\mathbb{R}$ lub $\mathbb{C}$, gdzie $\dim V = n < \infty$. Wówczas istnieje baza $V$ która jest bazą kanoniczną funkcjonału $G$.
\end{twierdzenie}
% no i tu jest konstruktywny dowód, który jest jednocześnie metodą sprowadzania do postaci kanonicznej. Ale jst długi :)
\begin{twierdzenie}
	Niech $B = \left\{v_1, v_2, \ldots, v_n\right\}, B' = \left\{v_1', v_2', \ldots, v_n'\right\}$ będą bazami w przestrzeni $n$\ppauza wymiarowej $V$. Jeśli
	\begin{equation}
		v_i' = \sum_{i = 1}^n p_{j, i}v_j,
	\end{equation}
	czyli $P = [p_{i, j}]$ jest macierzą przejścia z bazy $B$ do $B'$, to
	\begin{equation}
		x_i = \sum_{i = 1}^n p_{i, j}x_j',
	\end{equation}
	czyli współrzędne wyrażają się przez współrzędne nowe za pomocą macierzy $P$.
\end{twierdzenie}
\begin{wniosek}
	Wektory bazy przekształcają się wzdłuż kolumn, a współrzędne wektorów przekształcają się wzdłuż wierszy.
\end{wniosek}
\begin{twierdzenie}[prawo bezwładności form kwadratowych Sylvestera]
	Niech $\dim V = n < \infty$, gdzie $V$ jest przestrzenią liniową nad $\mathbb{R}$. Niech $B, B'$ \ppauza\ bazy kanoniczne funkcjonału kwadratowego $F$. Wtedy liczba współczynników dodatnich jest taka sama w obu bazach, podobnie liczba współczynników ujemnych.
\end{twierdzenie}
\begin{definicja}
	Forma kwadratowa nazywa się \emph{dodatnio określoną}, jeżeli wszystkie współczynniki w~postaci kanonicznej są dodatnie. Analogicznie definiujemy \emph{ujemną określoność, niedodatnią określoność} oraz \emph{nieujemną określoność}.
\end{definicja}
\begin{definicja}
	Forma kwadratową nazywamy \emph{określoną}, jeśli wszystkie współczynniki diagonalne w~postaci kanonicznej są niezerowe i~mają ten sam znak.
\end{definicja}
\begin{definicja}
	\emph{Sygnaturą} formy kwadratowej nazywamy parę $(p, q)$, gdzie $p$ jest liczbą współczynników dodatnich, a $q$ ujemnych w~twierdzeniu Sylvestera. Jak już wiemy, jest w~każdej bazie kanonicznej taka sama.
\end{definicja}
\begin{twierdzenie}
	Forma kwadratowa $F$ jest dodatnio określona wtedy i tylko wtedy, gdy
	\begin{equation}
		\left(\forall v\in V\setminus\left\{\vec 0\right\}\right) F(v) > 0.
	\end{equation}
	Jest nieujemnie określona, wtedy i tylko wtedy gdy
	\begin{equation}
		\left(\forall v\in V\right) F(v) \geq 0.
	\end{equation}
	Analogicznie dla ujemnej określoności i niedodatniej określoności.
\end{twierdzenie}
\begin{twierdzenie}
	Oznaczmy przez $\Delta_k$ wyznacznik minora $k\times k$ macierzy A, zawierającego pierwsza komórkę. Forma kwadratowa $F$ jest dodatnio określona wtedy i tylko wtedy gdy
	\begin{equation}
		\left(\forall i \in [n] \right) \Delta_i > 0.
	\end{equation}
\end{twierdzenie}
\begin{twierdzenie}
	Niech $F$ będzie rzeczywistą formą kwadratową postaci
	\begin{equation}
		F(v) = \sum_{i, j = 1}^{n} a_{i, j}x_ix_j
	\end{equation}
	i niech $\Delta_i$ będą wyznacznikami jak przedtem. Jeśli są one wszystkie niezerowe, to istnieje baza w której forma $F(v)$ przyjmuje postać
	\begin{equation}
		F(v) = \frac{\Delta_0}{\Delta_1}{y_1}^2 + \frac{\Delta_1}{\Delta_2}{y_2}^2 + \ldots + \frac{\Delta_{n-1}}{\Delta_n}{y_n}^2.
	\end{equation}
	gdzie $\Delta_0 = 1$.
\end{twierdzenie}
\begin{definicja}
	\emph{Formą hermitowską} na przestrzeni $V$ nad $\mathbb{C}$ nazywamy formę półtoraliniową spełniającą dla dowolnych $v, w \in V$
	\begin{equation}
		F(v, w) = \overline {F(w, v)}.
	\end{equation}
	Przykładem takiej funkcji dla $V = {\mathbb{C}}^n$ jest
	\begin{equation}
		F(v, w) = \sum_{i = 1}^n x_i\overline{y_i}.
	\end{equation}
\end{definicja}
Uwaga: ogólną postacią formy półtoraliniowej jest
\begin{equation}
	F(v, w) = \sum_{i, j = 1}^n a_{i, j}x_i\overline{y_j}.
\end{equation}
Jeśli forma jest hermitowska, to ta także powyższą postać, przy czym zachodzi warunek $a_{i, j} = \overline a_{j, i}$.
\begin{twierdzenie}
	W przestrzeni liniowej z~iloczynem skalarnym nad $\mathbb{C}$ istnieje baza kanoniczna formy kwadratowej hermitowskiej, to jest forma otrzymana z formy hermitowskiej $F\colon V\times V\to \mathbb{C}$ przez $\widetilde{F}(v) = F(v, v)$ ma postać kanoniczną (diagonalną).
	\begin{equation}
		\widetilde F(v) = \sum_{i = 1}^n a_{i, i}{|x_i|}^2, \quad \text{gdzie ${|x_i|}^2 = x_i\overline{x_i}$.}
	\end{equation}
\end{twierdzenie}
\section{Przestrzenie z iloczynem skalarnym}
\begin{definicja}
	Niech $\dim V = n < \infty$, oraz $B = \left\{e_1, e_2, \ldots, e_n\right\}$ \ppauza baza $V$. Zbiór $B^* = \left\{e^1, e^2, \ldots, e^n\right\}$ gdzie $e_i\colon V\to\mathbb{K}$ jest przekształceniem liniowym zdefiniowanym na bazie $B$ jako
	\begin{equation}
		e^j(e_k) = \delta_{j, k},
	\end{equation}
	nazywamy \emph{bazą dualną} do bazy $B$.
\end{definicja}
\begin{twierdzenie}
	Baza dualna jest bazą w $V^*$.
\end{twierdzenie}
\begin{definicja}
	Niech $V^*$ \ppauza przestrzeń dualna do $V$, gdzie $V$ jest przestrzenią unitarną lub Euklidesową. Dla każdego wektora $v\in V$ definiujemy funkcjonał $\Phi_v \in L(V, \mathbb{K}) = V^*$ przez
	\begin{equation}
		\Phi_v(w) = \left<w, v\right>.
	\end{equation}
\end{definicja}
\begin{twierdzenie}
	Niech $V$ będzie przestrzenią liniową z iloczynem skalarnym o~wymiarze $n < \infty$. Wtedy odwzorowanie $\Phi\colon V\to V^*$ zadane wzorem
	\begin{equation}
		\Phi(v) = \Phi_v
	\end{equation}
	jest izomorfizmem przestrzeni $V$ oraz $V^*$.
\end{twierdzenie}
\begin{definicja}
	Rzeczywistą macierz kwadratową $A \in M_n(\mathbb{R})$ nazywamy \emph{macierzą ortogonalną} jeżeli spełnia ana warunek
	\begin{equation}
		AA^T = \im.
	\end{equation}
	Uwaga: jeśli $A$ jest ortogonalna, to jest odwracalna i $A^T = A^{-1}$. Ponadto, $\det A = \pm 1$.
\end{definicja}
\begin{twierdzenie}
	Macierz przejścia z~bazy ortonormalnej do bazy ortonormalnej jest macierzą ortogonalną. Każda macierz ortogonalna jest macierzą przejścia z pewnej bazy ortonormalnej do pewnej bazy ortonormalnej.
\end{twierdzenie}
\begin{definicja}
	Przestrzeń liniową nad ciałem $\mathbb{C}$ z (zespolonym) iloczynem skalarnym nazywamy \emph{przestrzenią unitarną}.
\end{definicja}
\section{Przekształcenia liniowe w przestrzeniach unitarnych}
Okazuje się, że większość twierdzeń które mieliśmy dla przestrzeni Euklidesowych zachodzi też dla przestrzeni unitarnych. W~szczególności:
\begin{enumerate}
	\item w przestrzeni unitarnej istnieje norma indukowana przez iloczyn skalarny
	\begin{equation}
		\|x\| = \sqrt{\left<x, x\right>},
	\end{equation}
	\item zachodzi nierówność Cauchy'ego\ppauza Schwartza
	\begin{equation}
		\|x+y\| \leq \|x\| + \|y\|,
	\end{equation}
	\item każdy zbiór wektorów ortogonalnych można uzupełnić do bazy ortogonalnej,
	\item dla dowolnej podprzestrzeni $W\leq V$ zachodzi rozkład
	\begin{equation}
		V = W \oplus W^\perp.
	\end{equation}
\end{enumerate}
\begin{twierdzenie}
	Niech $B = \left\{e_1, e_2, \ldots, e_n\right\}$ \ppauza baza ortonormalna w~przestrzeni unitarnej $V$ oraz $\dim V = n < \infty$. Wtedy dla dowolnych $x, y\in V$ zachodzą wzory:
	\begin{align}
		x &= \sum_{i = 1}^n \left<x, e_i\right>e_i,\\
		\left<x, y\right> &= \sum_{i = 1}^n \left<x, e_i\right>\left<e_i, y\right>, \\
		{\|x\|}^2 &= \sum_{i = 1}^n {|\left<x, e_i\right>|}^2.
	\end{align}
\end{twierdzenie}
\begin{definicja}
	Jeżeli $A\in M_n(\mathbb{C})$, to \emph{macierzą sprzężoną} do macierzy $A$ nazywamy macierz
	\begin{equation}
		A^* = {\overline A}^T,
	\end{equation}
	czyli $[a_{i, j}]^* = [\overline{a_{j, i}}]$.
\end{definicja}
\begin{definicja}
	Macierz $U\in M_n(\mathbb{C})$ nazywamy \emph{macierzą unitarną}, jeśli spełnia
	\begin{equation}
		U^*U = \im.
	\end{equation}
	Uwaga: każda macierz unitarna jest nieosobliwa i $U^{-1} = U^*$. Ponadto $|\det U | = 1$.
\end{definicja}
\begin{twierdzenie}
	Macierz przejścia z~bazy ortonormalnej do bazy ortonormalnej w~przestrzeni unitarnej jest macierzą unitarną. Każda macierz unitarna jest macierzą przejścia z~pewnej bazy ortonormalnej do pewnej bazy ortonormalnej.
\end{twierdzenie}
\begin{twierdzenie}
	Kilka prostych własności macierzy unitarnych:
	\begin{enumerate}
		\item macierz unitarna o współczynnikach rzeczywistych jest ortogonalna, tzn. $U^TU = \im$,
		\item ${\left(A^*\right)}^* = A$,
		\item ${\left(AB\right)}^* = B^*A^*$,
		\item iloczyn macierzy unitarnych jest unitarny,
		\item macierz odwrotna do macierzy unitarnej jest unitarna.
	\end{enumerate}
\end{twierdzenie}
\begin{definicja}
	Niech będzie dane przekształcenie liniowe $T \in L(V)$, gdzie $V$ jest przestrzenią unitarną. Wtedy możemy zdefiniować formę półtoraliniową $F_T\colon V\times V\to \mathbb{C}$ wzorem
	\begin{equation}
		F_T(x, y) = \left<Tx, y\right>.
	\end{equation}
\end{definicja}
\begin{twierdzenie}
	Odwzorowanie $\psi\colon L(V)\to L(V\times V)$ zadane wzorem
	\begin{equation}
		\psi(T) = F_T
	\end{equation}
	jest bijekcją.
\end{twierdzenie}
% Moglibyśmy powiedzieć, że izomorfizmem, jeśli postrzegalibyśmy zbiór przekształceń dwuliniowych $L(V\times V)$ jako przestrzeń liniową?
\begin{twierdzenie}
	% uwaga: mogłem coś z tym twierdzeniem zepsuć, bo przepisywałem je poźniej bez notatek
	Niech dana będzie $n$\dywiz wymiarowa przestrzeń unitarna $V$, gdzie $n$ jest skończone. Ustalmy formę półtoraliniową $F$ na tej przestrzeni.
	Jeżeli macierz formy $F$ w~bazie ortonormalnej $B$ to $M(F)$, to macierz przekształcenia $T_F$, wyznaczonego przez formę $F$ za pomocą wzoru
	\begin{equation}
		F(x, y) = \left<T_F x, y\right>
	\end{equation} jest równa ${M(F)}^T$.
\end{twierdzenie}
\begin{definicja}
	Niech $T\in L(V)$. Wtedy przekształcenie $T^*\in L(V)$ zdefiniowane wzorem
	\begin{equation}
		\left<Tx, y\right> = \left<x, T^*y\right>
	\end{equation}
	nazywamy \emph{przekształceniem sprzężonym} do $T$.
\end{definicja}
\begin{twierdzenie}
	Przekształcenie $T^*$ jest dobrze zdefiniowane i~jeżeli $A$ jest macierzą przekształcenia $T$ w~bazie $B$, to $A^*$ jest macierzą przekształcenia $T^*$ w~tej bazie.
\end{twierdzenie}
\begin{twierdzenie}
	Jeśli $V$ jest przestrzenią unitarną oraz $T\in L(V)$ to
	\begin{equation}
		{(T^*)}^* = T
	\end{equation}
\end{twierdzenie}
\begin{definicja}
	Przekształcenie liniowe $T\in L(V)$ w przestrzeni unitarnej $V$ jest \emph{hermitowskie}, lub \emph{samosprzężone} jeżeli zachodzi
	\begin{equation}
		T = T^*.
	\end{equation}
\end{definicja}
\begin{twierdzenie}
	Wartości własne przekształcenia hermitowskiego są rzeczywiste.
\end{twierdzenie}
\begin{twierdzenie}
	Każde przekształcenie liniowe w~przestrzeni unitarnej można zapisać w~postaci
	\begin{equation}
		T = T_1 + \iu T_2,
	\end{equation}
	gdzie $T_1, T_2$ są hermitowskie.
\end{twierdzenie}
\begin{twierdzenie}
	Przekształcenie $U\in L(V)$ na przestrzeni unitarnej $V$ nazywamy \emph{unitarnym}, gdy
	\begin{equation}
		UU^* = U^*U = \mathrm{Id}.
	\end{equation}
\end{twierdzenie}
\begin{twierdzenie}
	Macierz przekształcenia unitarnego w~każdej bazie ortonormalnej jest macierzą unitarną.
\end{twierdzenie}
\begin{twierdzenie}
	Macierz przekształcenia hermitowskiego w~każdej bazie ortonormalnej jest macierzą hermitowską.
\end{twierdzenie}
\begin{twierdzenie}
	każde przekształcenie liniowe na przestrzeni unitarnej skończenie wymiarowej można przedstawić jako iloczyn przekształcenia hermitowskiego i~unitarnego.
\end{twierdzenie}
\begin{twierdzenie}
	Jeśli $U$ jest przekształceniem unitarnym, to jego wartości własne mają moduł równy $1$, czyli są postaci
	\begin{equation}
		\e^{\iu\varphi}, \quad \text{dla } \varphi \in \mathbb{R}.
	\end{equation}
\end{twierdzenie}
\begin{twierdzenie}
	Jeśli $U$ jest przekształceniem unitarnym, to
	\begin{equation}
		\left(\forall x, y \in V\right) \left<Ux, Uy\right> = \left<x, y\right>,
	\end{equation}
	czyli $U$ zachowuje iloczyn skalarny w~przestrzeni unitarnej. Jeżeli przekształcenie $U$ zachowuje iloczyn skalarny w~przestrzeni unitarnej, to jest to przekształcenie unitarne (warunki są równoważne, nawet czasem jako definicję przyjmuje się to twierdzenie).
\end{twierdzenie}
\begin{twierdzenie}
	Niech $T$ będzie przekształceniem hermitowskim w~unitarnej przestrzeni skończenie wymiarowej $V$. Jeśli $x$ jest wektorem własnym $T$, to przestrzeń wektorów ortogonalnych $W = {(\Lin(x))}^\perp$ jest podprzestrzenią niezmiennicza przestrzeni $V$ względem $T$.
\end{twierdzenie}
\begin{twierdzenie}[Diagonalizowalność przekształceń hermitowskich]
	Niech $T$ będzie przekształceniem hermitowskim w~unitarnej przestrzeni $n$\dywiz wymiarowej $V$. Wtedy istnieje $n$  parami ortogonalnych wektorów własnych tego przekształcenia, którym odpowiadają rzeczywiste wartości własne.
\end{twierdzenie}
\begin{definicja}
	Przekształcenie liniowe $T$ w~przestrzeni unitarnej nazywamy \emph{normalnym}, gdy
	\begin{equation}
		TT^* = T^*T.
	\end{equation}
\end{definicja}
\begin{twierdzenie}
	Każde przekształcenie normalne (a~zatem także unitarne oraz hermitowskie) jest diagonalizowalne.
\end{twierdzenie}
\section{Postać kanoniczna Jordana}
\begin{definicja}
	\emph{Klatką Jordana} nazywamy macierz postaci
	\begin{equation}
		K = \begin{bmatrix}
			\lambda & 1 & 0 & 0 & \cdots & 0 & 0 \\
			0 & \lambda & 1 & 0 & \cdots & 0 & 0 \\
			0 & 0 & \lambda & 1 & \cdots & 0 & 0 \\
			0 & 0 & 0 & \lambda & \cdots & 0 & 0 \\
			\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
			0 & 0 & 0 & 0 & \cdots & \lambda & 1 \\
			0 & 0 & 0 & 0 & \cdots & 0 & \lambda \\
		\end{bmatrix},
	\end{equation}
	czyli macierz, która ma na diagonali takie same wartości $\lambda$, ponad diagonalą same jedynki (dokładniej: komórka w $k$\dywiz tym wierszu i $(k+1)$\dywiz tej kolumnie jest jedynką) oraz zera w~pozostałych komórkach.
\end{definicja}
Kilka przykładów klatek Jordana:
\begin{gather}
	\begin{bmatrix}
		5
	\end{bmatrix},\quad
	\begin{bmatrix}
		-1 & \phantom{-}1 \\
		\phantom{-}0 & -1
	\end{bmatrix},\quad
	\begin{bmatrix}
		2 & 1 & 0 \\
		0 & 2 & 1 \\
		0 & 0 & 2
	\end{bmatrix},\quad
	\begin{bmatrix}
		3 & 1 & 0 & 0 \\
		0 & 3 & 1 & 0 \\
		0 & 0 & 3 & 1 \\
		0 & 0 & 0 & 3
	\end{bmatrix}.
\end{gather}
\begin{twierdzenie}
	Jeżeli $A \in M_n(\mathbb{C})$, to istnieje macierz nieosobliwa $P$, taka że
	\begin{equation}
		P^{-1}AP = \begin{bmatrix}
			K_1 & \mathbb{0} & \mathbb{0} & \cdots & \mathbb{0} \\
			\mathbb{0} & K_2 & \mathbb{0} & \cdots & \mathbb{0} \\
			\mathbb{0} & \mathbb{0} & K_3 & \cdots & \mathbb{0} \\
			\vdots & \vdots & \vdots & \ddots & \vdots \\
			\mathbb{0} & \mathbb{0} & \mathbb{0} & \cdots & K_m \\
		\end{bmatrix},
	\end{equation}
	gdzie $K_j$ są klatkami Jordana. Mogą, ale nie muszą mieć one różnych stałych $\lambda$ oraz mogę mieć różne wymiary. W~szczególności, jeśli wszystkie są wymiaru $1\times 1$, to $A$ jest diagonalizowalna.
\end{twierdzenie}
\begin{definicja}
	Przyjmujemy oznaczenie
	\begin{equation}
		N_\lambda^{(n)} = \Ker{\left(T-\lambda\mathrm{Id}\right)}^n.
	\end{equation}
	Elementy zbioru
	\begin{equation}
		N_\lambda^{(n+1)} \setminus N_\lambda^{(n)}
	\end{equation}
	nazywamy \emph{wektorami dołączonymi} rzędu $n$, dla $n\geq 1$.
\end{definicja}
\begin{definicja}
	Zbiór wektorów $\left\{v_1, v_2, \ldots v_n\right\}$ jest \emph{liniowo niezależny względem $N_\lambda^{(n)}$}, jeśli żadna kombinacja liniowa wektorów $v_1, v_2, \ldots, v_n$ nie należy do $N_\lambda^{(n)}$. \\W~skrócie: $\Lin\left(\left\{v_1, v_2, \ldots v_n\right\}\right) \cap N_\lambda^{(n)} = \{\vec 0\}$.
\end{definicja}
Aby sprowadzić macierz do postaci kanonicznej Jordana, najpierw znajdujemy wartości własne i~wektory własne. Jeśli mamy $n$ liniowo niezależnych wektorów własnych, to zadanie jest sprowadzone do diagonalizacji. Jeśli krotność geometryczna danej wartości własnej $\lambda$ (liczba liniowo niezależnych wektorów własnych jej odpowiadających) wynosi $k$, to powstanie $k$ klatek Jordana związanych z tą wartością własną. Będziemy szukać \emph{bazy kanonicznej Jordana}. Dokładnie $m$ wektorów tej bazy będzie pochodzić od wartości własnej $\lambda$, gdzie $m$ jest krotnością algebraiczną $\lambda$. Wektory te będą wektorami własnymi odpowiadającymi $\lambda$, oraz wektorami do nich dołączonymi, przy czym dla każdego $s$ zbiór przez nas wybranych wektorów dołączonych stopni od $s$ do $m$ ma być liniowo niezależny względem $N_\lambda^{(s)}$. Wówczas dla wektorów dołączonych stopnia najwyższego, kolejne (stopnia o~jeden mniej) możemy wyliczać przez przemnożenie przez macierz $T-\lambda\im$. Może się zdarzyć, że będziemy mieli kilka wektorów dołączonych danego rzędu. Będą one tworzyły swego rodzaju nitki. Wektory z~jednej nitki odpowiadają jednej klatce Jordana (więc w~ostatecznej bazie muszą być obok siebie). Kolejność także ma znaczenie: dla danej nitki w~ostatecznej bazie wypiszemy znalezione wektory w~kolejności od najmniejszego stopnia (odwrotnie, niż zostały wyznaczone).
\end{document}






